{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from prettytable import PrettyTable\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#set data path\n",
    "LOCAL_DATA_PATH = 'C:\\Users\\JoAnna\\political_history\\processed_data'\n",
    "SAVE_PATH = 'C:\\Users\\JoAnna\\political_history\\shibboleth\\pkl_objects'\n",
    "os.chdir(LOCAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data, perform train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "labels = pickle.load(open('bow_labels.pkl', \"r\"))\n",
    "text = pickle.load(open('bow_processed_text.pkl', \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train/test split of data (randomized)\n",
    "text_train, text_test, labels_train, labels_test = cross_validation.train_test_split(text, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: see how paragraphs cluster with party affiliation after TF-IDF  \n",
    "http://stackoverflow.com/questions/28160335/plot-a-document-tfidf-2d-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA:\n",
    "\n",
    "1) clustering by year, tf-idf, word2vec\n",
    "\n",
    "2) seperating clustering\n",
    "\n",
    "3) most frequent words - histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf vectorizer and numpy array\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "text_train_transformed = vectorizer.fit_transform(text_train).toarray()\n",
    "text_test_transformed  = vectorizer.transform(text_test).toarray()\n",
    "\n",
    "#test vectorizer\n",
    "#print len(vectorizer.get_feature_names())\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#feature_names[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [  10   17   26   32   34   37   39   47   48   54   58   65   67   76   79\n",
      "   80   85   87   88   90   96   97   99  109  112  113  114  118  121  124\n",
      "  125  126  131  135  136  146  161  171  189  190  201  203  212  218  229\n",
      "  239  244  245  246  255  274  276  307  313  324  355  366  371  379  383\n",
      "  389  394  398  410  411  414  416  431  436  438  446  447  448  452  464\n",
      "  470  490  495  502  505  515  518  528  529  530  536  537  547  558  561\n",
      "  564  573  575  578  583  587  589  594  595  596  597  607  612  616  650\n",
      "  654  664  673  675  678  681  685  690  696  699  700  720  733  734  753\n",
      "  758  766  768  777  779  786  791  794  795  796  806  809  813  815  817\n",
      "  843  846  848  850  862  865  866  875  876  880  888  890  895  903  907\n",
      "  916  917  927  931  932  933  937  959  966  975  983  984 1011 1019 1025\n",
      " 1033 1044 1049 1051 1067 1083 1085 1088 1100 1106 1108 1111 1116 1128 1129\n",
      " 1164 1174 1180 1184 1185 1207 1209 1212 1228 1230 1238 1260 1265 1303 1324\n",
      " 1325 1334 1335 1339 1344 1345 1361 1364 1365 1370 1392 1398 1401 1404 1409\n",
      " 1419 1429 1437 1440 1445 1446 1451 1468 1469 1476 1481 1483 1499 1509 1516\n",
      " 1525 1527 1530 1538 1551 1567 1571 1581 1591 1600 1607 1619 1625 1628 1639\n",
      " 1642 1646 1647 1649 1650 1658 1661 1678 1683 1684 1685 1686 1688 1714 1728\n",
      " 1740 1744 1752 1763 1764 1768 1788 1812 1813 1823 1840 1841 1852 1883 1884\n",
      " 1899 1901 1903 1914 1918 1925 1927 1929 1931 1939 1952 1975 1988 1990 1997\n",
      " 2001 2011 2031 2032 2043 2044 2060 2061 2070 2078 2084 2099 2100 2110 2113\n",
      " 2136 2155 2157 2169 2179 2183 2187 2192 2206 2215 2220 2231 2236 2237 2245\n",
      " 2246 2251 2254 2257 2261 2267 2272 2277 2281 2296 2310 2328 2329 2332 2337\n",
      " 2348 2351 2353 2358 2370 2371 2372 2374 2383 2406 2412 2420 2439 2453 2454\n",
      " 2457 2465 2479 2513 2531 2544 2551 2553 2563 2568 2576 2586 2591 2593 2594\n",
      " 2595 2605 2620 2622 2642 2650 2658 2665 2675 2677 2699 2711 2713 2714 2721\n",
      " 2722 2725 2729 2738 2741 2745 2748 2750 2775 2808 2809 2816 2820 2831 2833\n",
      " 2848 2849 2866 2872 2876 2890 2910 2926 2930 2934 2938 2940 2946 2947 2966\n",
      " 2975 2994 3001 3002 3004 3010 3012 3034 3035 3042 3043 3060 3061 3077 3080\n",
      " 3089 3114 3122 3123 3128 3132 3133 3139 3140 3142 3144 3148 3151 3159 3170\n",
      " 3171 3177 3178 3184 3188 3190 3203 3216 3219 3231 3250 3259 3266 3276 3277\n",
      " 3278 3281 3290 3291 3297 3300 3306 3314 3322 3323 3333 3340 3347 3364 3366\n",
      " 3400 3402 3403 3407 3425 3442 3444 3451 3455 3456 3466 3489 3493 3494 3495\n",
      " 3514 3516 3523 3531 3540 3560 3563 3571 3576 3577 3589 3605 3606 3610 3617\n",
      " 3621 3623 3624 3625 3637 3642 3647 3653 3656 3658 3662 3665 3668 3675 3679\n",
      " 3704 3731 3736 3745 3760 3761 3765 3772 3777 3783 3797 3801 3803 3820 3822\n",
      " 3841 3855 3859 3882 3887 3909 3916 3926 3930 3937 3941 3948 3953 3966 3967\n",
      " 3974 3983 3991 3995 4014 4021 4046 4049 4051 4056 4062 4064 4081 4112 4122\n",
      " 4124 4125 4134 4136 4159 4164 4168 4170 4180 4187 4189 4191 4193 4195 4209\n",
      " 4213 4226 4227 4229 4242 4246 4247 4252 4253 4254 4259 4269 4278 4281 4284\n",
      " 4294 4299 4300 4319 4327 4328 4336 4349 4353 4354 4370 4373 4396 4400 4413\n",
      " 4419 4423 4424 4432 4433 4446 4448 4459 4466 4487 4493 4499 4520 4523 4525\n",
      " 4532 4539 4560 4562 4563 4564 4574 4577 4584 4593 4598 4602 4604 4610 4612\n",
      " 4616 4624 4630 4647 4648 4654 4662 4677 4678 4686 4696 4715 4720 4725 4738\n",
      " 4739 4740 4759 4764 4765 4781 4802 4805 4810 4812 4813 4814 4825 4831 4837\n",
      " 4844 4845 4853 4854 4860 4861 4864 4865 4867 4873 4875 4879 4880 4885 4886\n",
      " 4887 4899 4900 4912 4926 4928 4940 4950 4962 4974 4989 4993 5000 5001 5007\n",
      " 5015 5019 5021 5027 5028 5032 5041 5049 5063 5085 5088 5093 5100 5102 5114\n",
      " 5135 5137 5139 5142 5144 5156 5157 5158 5161 5175 5193 5200 5201 5202 5203\n",
      " 5206 5207 5209 5210 5213 5214 5215 5220 5222 5229 5235 5238 5240 5243 5264\n",
      " 5271 5283 5285 5299 5313 5334 5365 5389 5393 5396 5401 5409 5447 5448 5473\n",
      " 5474 5480 5485 5489 5491 5496 5497] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [   2    8   11   16   18   30   43   44   45   50   51   57   74   86   89\n",
      "   93  101  120  122  123  134  143  149  155  156  159  160  164  165  170\n",
      "  181  183  187  202  206  214  216  227  236  237  257  269  272  275  302\n",
      "  314  322  330  333  338  339  344  395  400  402  403  407  412  419  421\n",
      "  424  427  430  450  454  465  466  477  481  483  488  496  499  503  522\n",
      "  524  531  532  555  556  568  571  582  592  598  602  603  614  628  631\n",
      "  639  642  661  669  670  682  688  691  702  714  722  725  736  737  738\n",
      "  761  797  798  800  808  810  811  814  822  832  834  837  853  863  885\n",
      "  886  897  936  949  954  985  987 1007 1016 1018 1020 1021 1032 1035 1039\n",
      " 1043 1079 1080 1084 1091 1092 1096 1097 1114 1126 1127 1130 1135 1146 1150\n",
      " 1159 1161 1171 1197 1199 1205 1210 1211 1225 1227 1237 1259 1275 1287 1289\n",
      " 1299 1309 1310 1326 1328 1330 1340 1351 1369 1371 1375 1379 1399 1407 1412\n",
      " 1422 1433 1443 1450 1452 1458 1462 1464 1479 1482 1485 1500 1501 1506 1510\n",
      " 1518 1523 1545 1550 1576 1582 1594 1595 1608 1620 1624 1648 1673 1676 1680\n",
      " 1681 1692 1702 1730 1749 1751 1765 1774 1782 1802 1807 1827 1834 1865 1878\n",
      " 1892 1898 1913 1924 1935 1944 1945 1956 1958 1963 1972 1979 1995 2010 2029\n",
      " 2033 2046 2048 2051 2058 2074 2077 2079 2080 2082 2085 2086 2088 2089 2092\n",
      " 2095 2102 2104 2108 2119 2126 2141 2142 2165 2177 2185 2198 2209 2212 2230\n",
      " 2235 2238 2247 2269 2278 2283 2285 2286 2289 2301 2304 2311 2317 2327 2333\n",
      " 2341 2342 2346 2361 2373 2385 2391 2413 2423 2431 2446 2448 2478 2486 2495\n",
      " 2508 2515 2517 2518 2521 2536 2547 2548 2550 2559 2575 2589 2599 2634 2646\n",
      " 2652 2653 2660 2666 2687 2690 2696 2701 2707 2716 2724 2732 2733 2767 2769\n",
      " 2771 2774 2779 2783 2785 2794 2796 2799 2800 2807 2815 2819 2825 2834 2837\n",
      " 2851 2878 2891 2895 2906 2908 2929 2936 2937 2943 2953 2965 2971 2981 2997\n",
      " 3019 3026 3054 3062 3083 3084 3108 3111 3118 3141 3152 3156 3183 3185 3186\n",
      " 3187 3194 3204 3210 3217 3218 3222 3226 3229 3232 3234 3237 3238 3244 3246\n",
      " 3251 3256 3261 3265 3270 3271 3272 3273 3274 3286 3294 3305 3307 3308 3342\n",
      " 3358 3362 3370 3376 3389 3396 3422 3436 3443 3461 3474 3481 3482 3491 3496\n",
      " 3497 3499 3515 3518 3519 3533 3553 3554 3559 3567 3568 3579 3595 3596 3602\n",
      " 3616 3620 3628 3648 3664 3669 3673 3678 3683 3689 3692 3695 3700 3702 3707\n",
      " 3718 3723 3730 3732 3741 3744 3751 3755 3756 3775 3795 3798 3804 3809 3817\n",
      " 3838 3843 3884 3888 3895 3897 3898 3905 3907 3908 3917 3919 3944 3946 3951\n",
      " 3959 3968 3971 3988 3990 4007 4011 4012 4018 4019 4025 4030 4032 4044 4047\n",
      " 4083 4086 4093 4098 4109 4110 4119 4128 4131 4138 4167 4169 4188 4194 4203\n",
      " 4205 4220 4221 4222 4235 4243 4245 4266 4270 4279 4286 4302 4303 4304 4308\n",
      " 4317 4321 4331 4334 4360 4362 4372 4376 4386 4389 4398 4407 4408 4410 4414\n",
      " 4420 4426 4440 4444 4454 4484 4490 4495 4497 4501 4502 4504 4505 4519 4527\n",
      " 4531 4545 4546 4547 4554 4585 4589 4591 4594 4595 4626 4628 4631 4637 4643\n",
      " 4644 4687 4689 4699 4712 4721 4723 4732 4758 4761 4770 4773 4777 4786 4791\n",
      " 4797 4800 4811 4824 4878 4881 4883 4884 4891 4897 4903 4904 4913 4938 4944\n",
      " 4948 4958 4964 4976 4977 4981 5002 5031 5033 5044 5045 5052 5083 5087 5090\n",
      " 5096 5108 5115 5126 5130 5132 5138 5141 5145 5146 5147 5151 5162 5166 5167\n",
      " 5181 5186 5198 5231 5248 5259 5260 5282 5290 5297 5306 5310 5314 5317 5320\n",
      " 5321 5323 5331 5333 5335 5349 5361 5367 5368 5376 5381 5398 5407 5416 5428\n",
      " 5429 5430 5435 5440 5472 5479 5486 5490 5499 5508 5509 5510 5511 5512 5515] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [   1    5    9   21   22   25   29   40   41   46   49   53   56   61   81\n",
      "   82  104  117  138  141  142  166  172  180  186  188  193  211  215  223\n",
      "  230  231  233  235  241  247  251  252  262  283  328  334  341  351  354\n",
      "  390  405  406  428  429  432  442  456  458  472  494  525  526  534  535\n",
      "  545  550  552  553  569  580  585  604  606  620  625  626  638  640  644\n",
      "  651  652  659  662  668  683  695  708  712  717  723  729  746  748  751\n",
      "  754  755  756  764  767  782  799  802  805  812  825  830  841  847  857\n",
      "  860  861  872  877  887  892  923  938  940  957  958  960  979  980  981\n",
      "  996 1006 1014 1045 1047 1052 1056 1059 1064 1068 1078 1082 1087 1099 1103\n",
      " 1112 1113 1120 1137 1167 1173 1186 1189 1191 1194 1204 1222 1231 1242 1243\n",
      " 1247 1261 1266 1279 1284 1288 1296 1297 1298 1301 1317 1329 1332 1333 1337\n",
      " 1348 1356 1357 1358 1359 1360 1363 1367 1389 1391 1405 1408 1414 1418 1427\n",
      " 1432 1439 1441 1447 1448 1457 1463 1465 1473 1477 1480 1493 1494 1502 1521\n",
      " 1532 1539 1555 1556 1561 1563 1573 1574 1575 1579 1580 1584 1588 1590 1596\n",
      " 1597 1603 1609 1613 1621 1627 1630 1635 1637 1640 1641 1657 1663 1671 1675\n",
      " 1690 1693 1697 1709 1710 1731 1737 1750 1754 1755 1756 1761 1779 1795 1804\n",
      " 1817 1822 1826 1828 1843 1846 1848 1885 1887 1906 1908 1920 1934 1941 1959\n",
      " 1965 1974 1980 1984 1986 1994 1996 1999 2004 2019 2022 2028 2034 2040 2041\n",
      " 2054 2062 2064 2066 2072 2094 2129 2131 2143 2147 2152 2153 2161 2168 2171\n",
      " 2180 2182 2199 2218 2222 2244 2259 2263 2266 2274 2284 2315 2319 2335 2364\n",
      " 2367 2369 2376 2384 2388 2390 2395 2396 2407 2411 2424 2430 2436 2440 2451\n",
      " 2452 2460 2461 2467 2468 2470 2473 2480 2490 2501 2502 2505 2514 2522 2525\n",
      " 2526 2529 2537 2539 2546 2562 2566 2571 2577 2578 2579 2598 2601 2607 2608\n",
      " 2612 2615 2618 2626 2627 2631 2639 2654 2656 2688 2698 2717 2723 2728 2730\n",
      " 2746 2762 2776 2795 2829 2860 2861 2867 2868 2870 2871 2886 2892 2911 2920\n",
      " 2921 2928 2932 2939 2944 2951 2954 2955 2970 2985 2987 3000 3003 3005 3018\n",
      " 3029 3037 3040 3046 3057 3066 3085 3087 3088 3099 3100 3105 3107 3110 3143\n",
      " 3146 3155 3161 3167 3175 3176 3179 3180 3196 3197 3202 3215 3225 3228 3240\n",
      " 3258 3262 3269 3279 3288 3295 3316 3328 3330 3332 3337 3338 3341 3343 3344\n",
      " 3346 3355 3368 3369 3371 3373 3374 3377 3381 3387 3394 3399 3408 3410 3412\n",
      " 3414 3419 3420 3446 3450 3453 3467 3471 3476 3477 3498 3500 3502 3507 3529\n",
      " 3532 3543 3550 3557 3558 3561 3566 3569 3570 3575 3585 3592 3597 3600 3609\n",
      " 3627 3663 3666 3667 3674 3676 3686 3699 3701 3706 3709 3711 3724 3734 3738\n",
      " 3747 3767 3769 3779 3780 3789 3802 3811 3814 3818 3832 3835 3847 3864 3872\n",
      " 3893 3903 3914 3920 3923 3934 3936 3943 3945 3973 3986 3989 4006 4010 4040\n",
      " 4048 4052 4054 4067 4071 4077 4079 4090 4114 4118 4140 4145 4158 4162 4173\n",
      " 4175 4185 4196 4199 4210 4214 4224 4234 4237 4239 4240 4265 4282 4291 4296\n",
      " 4307 4310 4316 4322 4323 4324 4326 4339 4374 4385 4392 4394 4397 4399 4403\n",
      " 4404 4406 4409 4411 4416 4427 4434 4438 4445 4451 4458 4470 4472 4483 4498\n",
      " 4506 4510 4518 4521 4522 4537 4540 4541 4548 4551 4588 4597 4601 4614 4615\n",
      " 4622 4629 4638 4640 4655 4663 4666 4668 4669 4671 4681 4690 4691 4700 4702\n",
      " 4703 4707 4708 4731 4735 4742 4743 4746 4748 4754 4772 4774 4775 4783 4792\n",
      " 4799 4801 4806 4815 4819 4820 4830 4836 4847 4870 4874 4890 4910 4916 4919\n",
      " 4925 4929 4945 4946 4949 4954 4956 4966 4967 4973 4996 5011 5016 5024 5026\n",
      " 5035 5039 5047 5055 5056 5059 5062 5069 5081 5084 5089 5097 5098 5112 5113\n",
      " 5117 5119 5125 5129 5134 5136 5149 5163 5171 5172 5182 5187 5188 5190 5194\n",
      " 5197 5199 5205 5211 5226 5227 5234 5241 5245 5249 5252 5258 5284 5305 5307\n",
      " 5319 5322 5327 5339 5375 5377 5391 5400 5403 5408 5417 5419 5423 5443 5456\n",
      " 5464 5465 5469 5482 5483 5484 5498] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection__select__percentile': 0.25, 'feature_selection__pca__n_components': 100}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.32      0.45       600\n",
      "          1       0.56      0.90      0.69       572\n",
      "\n",
      "avg / total       0.67      0.60      0.57      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#build classifier pipeline\n",
    "select = SelectPercentile(f_classif)\n",
    "pca = PCA()\n",
    "feature_selection = FeatureUnion([('select', select), ('pca', pca)],\n",
    "                    transformer_weights={'pca': 10})\n",
    "clfNB = GaussianNB()\n",
    "\n",
    "steps1 = [('feature_selection', feature_selection),\n",
    "        ('naive_bayes', clfNB)]\n",
    "\n",
    "pipeline1 = sklearn.pipeline.Pipeline(steps1)\n",
    "\n",
    "#search for best parameters\n",
    "parameters1 = dict(feature_selection__select__percentile=[.05, .1, .25], \n",
    "              feature_selection__pca__n_components=[10, 50, 100])\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline1, param_grid=parameters1)\n",
    "\n",
    "#because tf-idf vectorizer isn't in this pipeline, fit/predict on transformed data\n",
    "cv.fit(text_train_transformed, labels_train)\n",
    "pred = cv.predict(text_test_transformed)\n",
    "\n",
    "print cv.best_params_\n",
    "\n",
    "#pipeline.fit(features_train, labels_train)\n",
    "#pred = pipeline.predict(features_test)\n",
    "report = sklearn.metrics.classification_report(labels_test, pred)\n",
    "print report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60409556314\n"
     ]
    }
   ],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(labels_test, pred)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the steps of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up scoring function and table\n",
    "scoring_table = PrettyTable(['pipeline_name', 'accuracy', 'precision', 'recall', 'auc'])\n",
    "\n",
    "def scoring_function(pipeline_name, test_labels, prediction):\n",
    "    \"\"\"\n",
    "    runs evaluation metrics on prediction from classifier\n",
    "    Args:\n",
    "        labels from the test data set, prediction from classifier     \n",
    "    Returns:\n",
    "        prints scoring functions, appends scores to scoring dataframe\n",
    "    \"\"\"\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_labels, prediction)\n",
    "    precision = sklearn.metrics.precision_score(test_labels, prediction)\n",
    "    recall = sklearn.metrics.recall_score(test_labels, prediction)\n",
    "    auc = sklearn.metrics.roc_auc_score(test_labels, prediction)\n",
    "    print \"Validation Metrics for %s: accuracy: %s, precision: %s, recall: %s, auc: %s\"%(pipeline_name, accuracy, precision, recall, auc)\n",
    "    \n",
    "    scoring_table.add_row([pipeline_name, accuracy, precision, recall, auc])\n",
    "    return scoring_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics for test1: accuracy: 0.60409556314, precision: 0.558441558442, recall: 0.902097902098, auc: 0.611048951049\n",
      "+---------------+---------------+----------------+----------------+----------------+\n",
      "| pipeline_name |    accuracy   |   precision    |     recall     |      auc       |\n",
      "+---------------+---------------+----------------+----------------+----------------+\n",
      "|     test1     | 0.60409556314 | 0.558441558442 | 0.902097902098 | 0.611048951049 |\n",
      "+---------------+---------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "#test scoring function using test classifier above\n",
    "scoring_function('test1', labels_test, pred)\n",
    "print scoring_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set-up generic grid-search cv function\n",
    "def gridsearch_pipeline(pipeline_name, train_data, train_labels, test_data, pipeline_steps, parameters):\n",
    "    \"\"\"\n",
    "    generic function to run gridsearchcv on an input dataset, pipeline, and parameters\n",
    "    Args:\n",
    "        data separated into features/labels and train/test\n",
    "        steps of the pipeline\n",
    "        parameters for gridsearchcv\n",
    "    Returns:\n",
    "        best parameters from gridsearch, prediction for test features\n",
    "    \"\"\"\n",
    "    #pipeline\n",
    "    pipe = sklearn.pipeline.Pipeline(pipeline_steps)\n",
    "    \n",
    "    #gridsearch\n",
    "    cv = sklearn.grid_search.GridSearchCV(pipe, param_grid=parameters)\n",
    "    cv.fit(train_data, train_labels)\n",
    "    pred = cv.predict(test_data)\n",
    "    print cv.best_params_\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Put together pieces of classifier\n",
    "\n",
    "#tf-idf vectorizer\n",
    "vectorizer1 = TfidfVectorizer(sublinear_tf=True)\n",
    "vectorizer2 = TfidfVectorizer(max_df = 1, min_df = 0, sublinear_tf=True)\n",
    "vectorizer3 = TfidfVectorizer(ngram_range = (1,3), sublinear_tf=True)\n",
    "vectorizer4 = TfidfVectorizer(max_df = 0.8, min_df = 0.2, ngram_range = (1,3), sublinear_tf=True)\n",
    "\n",
    "#feature selection\n",
    "select = SelectPercentile(f_classif)\n",
    "pca = PCA()\n",
    "feature_selection = FeatureUnion([('select', select), ('pca', pca)],\n",
    "                    transformer_weights={'pca': 10})\n",
    "\n",
    "#classifier\n",
    "clfNB = GaussianNB()\n",
    "clfAdaBoost = AdaBoostClassifier(random_state = 42)\n",
    "clfLR = LogisticRegression(random_state=42, solver='sag')\n",
    "clfSVM = SGDClassifier(loss='modified_huber', penalty='l2', n_iter=200, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Classifiers - unigrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__n_components': 500}\n",
      "Validation Metrics for test2: accuracy: 0.621160409556, precision: 0.591690544413, recall: 0.722027972028, auc: 0.623513986014\n",
      "+---------------+----------------+----------------+----------------+----------------+\n",
      "| pipeline_name |    accuracy    |   precision    |     recall     |      auc       |\n",
      "+---------------+----------------+----------------+----------------+----------------+\n",
      "|     test1     | 0.60409556314  | 0.558441558442 | 0.902097902098 | 0.611048951049 |\n",
      "|     test2     | 0.621160409556 | 0.591690544413 | 0.722027972028 | 0.623513986014 |\n",
      "+---------------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "#test2 - GaussianNB, simple vectorizer, PCA\n",
    "steps = [\n",
    "         ('feature_pick', pca),\n",
    "         ('classifier', clfNB)]\n",
    "\n",
    "params = dict(feature_pick__n_components=[100, 200, 500])\n",
    "\n",
    "prediction = gridsearch_pipeline('test2', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test2', labels_test, prediction)\n",
    "print scoring_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 10}\n",
      "Validation Metrics for test3: accuracy: 0.695392491468, precision: 0.681895093063, recall: 0.704545454545, auc: 0.695606060606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test3 - GaussianNB, simple vectorizer, selectPercentile\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfNB)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[7, 10, 15])\n",
    "\n",
    "prediction = gridsearch_pipeline('test3', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test3', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection__select__percentile': 10, 'feature_selection__pca__n_components': 50}\n",
      "Validation Metrics for test4: accuracy: 0.698805460751, precision: 0.678629690049, recall: 0.727272727273, auc: 0.69946969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test4 - GaussianNB, simple vectorizer, Feature Union\n",
    "steps = [\n",
    "         ('feature_selection', feature_selection),\n",
    "         ('classifier', clfNB)]\n",
    "\n",
    "params = dict(feature_selection__select__percentile=[5, 10, 15], \n",
    "              feature_selection__pca__n_components=[50, 100, 200])\n",
    "\n",
    "prediction = gridsearch_pipeline('test4', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test4', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__learning_rate': 1, 'classifier__n_estimators': 50, 'feature_pick__n_components': 200}\n",
      "Validation Metrics for test5: accuracy: 0.602389078498, precision: 0.589225589226, recall: 0.611888111888, auc: 0.602610722611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test5 - AdaBoost, simple vectorizer, PCA\n",
    "steps = [\n",
    "         ('feature_pick', pca),\n",
    "         ('classifier', clfAdaBoost)]\n",
    "\n",
    "params = dict(feature_pick__n_components=[100, 200, 500],\n",
    "              classifier__n_estimators=[10, 20, 50],\n",
    "              classifier__learning_rate=[0.1, 1, 1.5])\n",
    "\n",
    "prediction = gridsearch_pipeline('test5', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test5', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__learning_rate': 1, 'classifier__n_estimators': 50, 'feature_pick__percentile': 5}\n",
      "Validation Metrics for test6: accuracy: 0.65614334471, precision: 0.606289308176, recall: 0.842657342657, auc: 0.660495337995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tes6 - AdaBoost, simple vectorizer, selectPercentile\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfAdaBoost)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[5, 10, 20],\n",
    "              classifier__n_estimators=[10, 20, 50],\n",
    "              classifier__learning_rate=[0.1, 1, 1.5])\n",
    "\n",
    "prediction = gridsearch_pipeline('test6', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test6', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__learning_rate': 1, 'classifier__n_estimators': 50, 'feature_selection__pca__n_components': 100, 'feature_selection__select__percentile': 10}\n",
      "Validation Metrics for test7: accuracy: 0.662969283276, precision: 0.635114503817, recall: 0.727272727273, auc: 0.66446969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test7 - adaboost, simple vectorizer, Feature Union\n",
    "steps = [\n",
    "         ('feature_selection', feature_selection),\n",
    "         ('classifier', clfAdaBoost)]\n",
    "\n",
    "params = dict(feature_selection__select__percentile=[5, 10, 15], \n",
    "              feature_selection__pca__n_components=[50, 100, 200],\n",
    "              classifier__n_estimators=[10, 20, 50],\n",
    "              classifier__learning_rate=[0.1, 1, 1.5])\n",
    "\n",
    "prediction = gridsearch_pipeline('test7', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test7', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__alpha': 0.001, 'feature_pick__n_components': 500}\n",
      "Validation Metrics for test8: accuracy: 0.692832764505, precision: 0.68661971831, recall: 0.681818181818, auc: 0.692575757576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test8 - svm, simple vectorizer, PCA\n",
    "steps = [\n",
    "         ('feature_pick', pca),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_pick__n_components=[100, 200, 500],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test8', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test8', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 15, 'classifier__alpha': 0.001}\n",
      "Validation Metrics for test9: accuracy: 0.704778156997, precision: 0.692176870748, recall: 0.711538461538, auc: 0.704935897436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test9 - svm, simple vectorizer, selectPercentile\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[5, 10, 15],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test9', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test9', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection__pca__n_components': 200, 'classifier__alpha': 0.001, 'feature_selection__select__percentile': 10}\n",
      "Validation Metrics for test10: accuracy: 0.684300341297, precision: 0.672945205479, recall: 0.687062937063, auc: 0.684364801865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test10 - svm, simple vectorizer, Feature Union\n",
    "steps = [\n",
    "         ('feature_selection', feature_selection),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_selection__select__percentile=[5, 10, 15], \n",
    "              feature_selection__pca__n_components=[100, 200, 500],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test10', text_train_transformed, labels_train, text_test_transformed, steps, params)\n",
    "scoring_function('test10', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB with select percentile and SVM give the highest accuracy and auc scores. I'll optimize these with tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688\n"
     ]
    }
   ],
   "source": [
    "#new vectorizer\n",
    "text_train_transformed2 = vectorizer2.fit_transform(text_train).toarray()\n",
    "text_test_transformed2  = vectorizer2.transform(text_test).toarray()\n",
    "print len(text_train_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [   4    7   12   15   16   17   18   24   25   28   31   32   34   35   36\n",
      "   39   41   42   44   46   47   50   51   52   53   54   56   59   60   61\n",
      "   62   64   65   70   74   79   87   88   90   92   98  100  105  107  108\n",
      "  112  116  118  119  120  123  134  135  136  137  138  139  141  146  147\n",
      "  149  156  158  160  162  164  167  172  174  177  179  180  183  184  185\n",
      "  189  190  191  196  200  201  204  206  207  208  209  215  216  218  228\n",
      "  231  235  238  239  240  241  244  246  249  255  256  263  267  269  271\n",
      "  272  273  275  276  277  278  279  285  287  289  291  292  299  300  302\n",
      "  306  308  309  310  314  315  317  319  320  321  322  324  325  326  327\n",
      "  329  337  338  342  343  346  349  352  356  359  363  369  371  376  378\n",
      "  379  383  387  388  399  400  401  409  410  413  417  420  425  426  436\n",
      "  440  441  446  447  449  451  452  458  459  462  467  468  470  471  477\n",
      "  482  484  487  488  492  500  501  503  507  509  511  515  519  520  527\n",
      "  528  534  539  541  544  547  549  553  556  557  558  560  561  563  564\n",
      "  569  572  573  574  575  582  583  586  587  591  595  597  600  603  609\n",
      "  613  616  620  624  625  627  628  629  630  641  646  647  651  658  659\n",
      "  663  668  669  673  677  680  687  690  693  699  702  705  708  710  711\n",
      "  714  717  719  721  723  724  726  727  729  730  731  733  735  736  738\n",
      "  747  753  754  756  760  761  762  763  767  768  771  779  781  783  789\n",
      "  795  796  799  805  813  823  826  827  830  832  834  835  836  837  840\n",
      "  844  845  849  850  855  857  859  860  866  869  870  871  874  875  877\n",
      "  881  882  884  885  890  901  902  904  908  909  912  916  920  921  924\n",
      "  930  934  937  939  942  944  947  948  954  957  960  963  964  966  967\n",
      "  971  972  974  978  980  981  986  994  996  997  998  999 1000 1001 1003\n",
      " 1004 1006 1007 1011 1014 1017 1018 1022 1026 1027 1032 1035 1038 1044 1055\n",
      " 1059 1064 1065 1066 1068 1071 1074 1076 1079 1081 1084 1086 1091 1095 1096\n",
      " 1110 1111 1112 1113 1119 1121 1125 1126 1128 1136 1138 1139 1140 1147 1149\n",
      " 1152 1154 1157 1165 1167 1172 1174 1175 1176 1182 1184 1186 1188 1189 1190\n",
      " 1191 1194 1195 1197 1198 1199 1200 1203 1206 1210 1217 1225 1228 1235 1236\n",
      " 1239 1241 1246 1247 1249 1256 1257 1261 1262 1263 1266 1273 1275 1278 1279\n",
      " 1282 1286 1288 1290 1292 1297 1298 1306 1311 1314 1315 1318 1319 1320 1324\n",
      " 1332 1336 1337 1338 1341 1345 1347 1349 1351 1354 1357 1358 1360 1364 1365\n",
      " 1370 1376 1379 1380 1381 1382 1383 1386 1388 1390 1392 1396 1405 1411 1412\n",
      " 1415 1417 1418 1421 1422 1428 1438 1440 1441 1442 1445 1448 1449 1453 1454\n",
      " 1458 1462 1470 1472 1473 1476 1484 1485 1486 1487 1488 1489 1494 1498 1500\n",
      " 1501 1502 1505 1509 1516 1517 1518 1519 1525 1529 1535 1538 1542 1543 1544\n",
      " 1551 1553 1554 1560 1567 1569 1571 1572 1573 1578 1580 1582 1583 1584 1586\n",
      " 1587 1588 1589 1590 1591 1594 1598 1599 1600 1602 1603 1607 1611 1612 1615\n",
      " 1621 1625 1631 1633 1634 1637 1638 1639 1641 1642 1644 1647 1651 1657 1661\n",
      " 1663 1666 1670 1671 1675 1684 1686 1688 1690 1691 1696 1697 1698 1699 1705\n",
      " 1710 1715 1716 1717 1718 1720 1721 1722 1724 1725 1726 1727 1730 1733 1734\n",
      " 1735 1737 1745 1747 1749 1752 1757 1767 1770 1777 1779 1780 1783 1787 1796\n",
      " 1801 1802 1804 1808 1810 1812 1813 1814] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [   2    5    6    8   14   20   21   22   26   27   30   33   40   43   45\n",
      "   48   55   57   58   63   69   71   72   73   75   76   78   82   83   85\n",
      "   91   93   95   97  104  114  115  117  121  122  125  126  128  129  131\n",
      "  142  143  145  148  150  151  152  155  161  165  166  169  170  171  175\n",
      "  176  178  181  186  187  195  197  199  205  210  211  212  217  222  223\n",
      "  226  233  237  242  245  247  251  252  257  258  259  268  280  281  283\n",
      "  286  288  290  293  295  296  297  303  307  311  312  318  328  332  333\n",
      "  344  348  350  351  353  354  355  366  367  370  372  373  374  382  385\n",
      "  386  389  390  392  393  394  395  397  406  407  411  412  415  416  419\n",
      "  424  428  429  431  435  437  438  442  444  450  461  463  464  465  469\n",
      "  473  474  478  481  486  491  493  495  496  498  505  508  510  512  514\n",
      "  516  517  518  522  523  531  537  542  545  546  559  568  570  571  579\n",
      "  584  588  590  596  598  599  601  602  607  614  615  619  623  626  632\n",
      "  634  635  636  638  642  649  653  657  664  665  667  675  676  678  679\n",
      "  681  682  683  684  685  688  689  691  694  695  700  704  709  712  715\n",
      "  716  720  722  725  728  739  740  742  743  744  745  746  748  750  752\n",
      "  757  758  759  764  769  773  776  782  784  787  791  792  804  807  809\n",
      "  812  814  815  816  817  821  825  828  833  838  848  851  852  856  858\n",
      "  861  863  864  867  868  872  879  880  887  888  889  892  893  894  895\n",
      "  897  898  899  900  903  905  906  910  911  913  922  925  927  928  929\n",
      "  936  940  941  945  950  953  956  961  969  970  976  979  982  983  991\n",
      "  993  995 1002 1008 1010 1021 1023 1024 1025 1028 1033 1034 1036 1037 1039\n",
      " 1041 1043 1045 1046 1047 1048 1050 1051 1052 1053 1056 1058 1061 1062 1063\n",
      " 1069 1072 1075 1077 1078 1088 1093 1094 1099 1103 1107 1109 1117 1118 1120\n",
      " 1127 1131 1134 1135 1137 1141 1142 1144 1148 1150 1151 1156 1160 1161 1164\n",
      " 1169 1170 1178 1181 1185 1187 1193 1196 1202 1207 1208 1212 1213 1215 1221\n",
      " 1222 1224 1226 1230 1232 1233 1234 1240 1245 1250 1251 1254 1260 1267 1268\n",
      " 1269 1271 1272 1276 1284 1285 1287 1289 1291 1294 1296 1300 1302 1303 1304\n",
      " 1305 1307 1308 1310 1312 1325 1326 1328 1329 1330 1331 1335 1339 1340 1348\n",
      " 1350 1356 1359 1363 1367 1368 1372 1377 1378 1385 1387 1389 1393 1397 1398\n",
      " 1399 1401 1404 1406 1413 1414 1419 1420 1424 1425 1426 1429 1433 1434 1436\n",
      " 1439 1443 1451 1457 1459 1460 1463 1464 1465 1466 1469 1474 1475 1480 1483\n",
      " 1490 1492 1493 1495 1496 1506 1507 1510 1511 1514 1515 1526 1536 1537 1540\n",
      " 1550 1552 1555 1556 1559 1561 1563 1565 1570 1577 1593 1595 1596 1597 1604\n",
      " 1605 1614 1616 1619 1624 1626 1629 1630 1635 1643 1645 1648 1649 1652 1660\n",
      " 1662 1665 1667 1672 1679 1681 1682 1687 1689 1692 1693 1695 1700 1702 1703\n",
      " 1706 1707 1713 1731 1739 1743 1744 1746 1750 1751 1754 1756 1758 1759 1761\n",
      " 1762 1764 1765 1766 1769 1771 1772 1774 1776 1781 1785 1788 1791 1792 1793\n",
      " 1794 1800 1803 1809 1811 1816 1817 1818 1819 1820 1821 1822] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [   0    1    3    9   10   11   13   19   23   29   37   38   49   66   67\n",
      "   68   77   80   81   84   86   89   94   96   99  101  102  103  106  109\n",
      "  110  111  113  124  127  130  132  133  140  144  153  154  157  159  163\n",
      "  168  173  182  188  192  193  194  198  202  203  213  214  219  220  221\n",
      "  224  225  227  229  230  232  234  236  243  248  250  253  254  260  261\n",
      "  262  264  265  266  270  274  282  284  294  298  301  304  305  313  316\n",
      "  323  330  331  334  335  336  339  340  341  345  347  357  358  360  361\n",
      "  362  364  365  368  375  377  380  381  384  391  396  398  402  403  404\n",
      "  405  408  414  418  421  422  423  427  430  432  433  434  439  443  445\n",
      "  448  453  454  455  456  457  460  466  472  475  476  479  480  483  485\n",
      "  489  490  494  497  499  502  504  506  513  521  524  525  526  529  530\n",
      "  532  533  535  536  538  540  543  548  550  551  552  554  555  562  565\n",
      "  566  567  576  577  578  580  581  585  589  592  593  594  604  605  606\n",
      "  608  610  611  612  617  618  621  622  631  633  637  639  640  643  644\n",
      "  645  648  650  652  654  655  656  660  661  662  666  670  671  672  674\n",
      "  686  692  696  697  698  701  703  706  707  713  718  732  734  737  741\n",
      "  749  751  755  765  766  770  772  774  775  777  778  780  785  786  788\n",
      "  790  793  794  797  798  800  801  802  803  806  808  810  811  818  819\n",
      "  820  822  824  829  831  839  841  842  843  846  847  853  854  862  865\n",
      "  873  876  878  883  886  891  896  907  914  915  917  918  919  923  926\n",
      "  931  932  933  935  938  943  946  949  951  952  955  958  959  962  965\n",
      "  968  973  975  977  984  985  987  988  989  990  992 1005 1009 1012 1013\n",
      " 1015 1016 1019 1020 1029 1030 1031 1040 1042 1049 1054 1057 1060 1067 1070\n",
      " 1073 1080 1082 1083 1085 1087 1089 1090 1092 1097 1098 1100 1101 1102 1104\n",
      " 1105 1106 1108 1114 1115 1116 1122 1123 1124 1129 1130 1132 1133 1143 1145\n",
      " 1146 1153 1155 1158 1159 1162 1163 1166 1168 1171 1173 1177 1179 1180 1183\n",
      " 1192 1201 1204 1205 1209 1211 1214 1216 1218 1219 1220 1223 1227 1229 1231\n",
      " 1237 1238 1242 1243 1244 1248 1252 1253 1255 1258 1259 1264 1265 1270 1274\n",
      " 1277 1280 1281 1283 1293 1295 1299 1301 1309 1313 1316 1317 1321 1322 1323\n",
      " 1327 1333 1334 1342 1343 1344 1346 1352 1353 1355 1361 1362 1366 1369 1371\n",
      " 1373 1374 1375 1384 1391 1394 1395 1400 1402 1403 1407 1408 1409 1410 1416\n",
      " 1423 1427 1430 1431 1432 1435 1437 1444 1446 1447 1450 1452 1455 1456 1461\n",
      " 1467 1468 1471 1477 1478 1479 1481 1482 1491 1497 1499 1503 1504 1508 1512\n",
      " 1513 1520 1521 1522 1523 1524 1527 1528 1530 1531 1532 1533 1534 1539 1541\n",
      " 1545 1546 1547 1548 1549 1557 1558 1562 1564 1566 1568 1574 1575 1576 1579\n",
      " 1581 1585 1592 1601 1606 1608 1609 1610 1613 1617 1618 1620 1622 1623 1627\n",
      " 1628 1632 1636 1640 1646 1650 1653 1654 1655 1656 1658 1659 1664 1668 1669\n",
      " 1673 1674 1676 1677 1678 1680 1683 1685 1694 1701 1704 1708 1709 1711 1712\n",
      " 1714 1719 1723 1728 1729 1732 1736 1738 1740 1741 1742 1748 1753 1755 1760\n",
      " 1763 1768 1773 1775 1778 1782 1784 1786 1789 1790 1795 1797 1798 1799 1805\n",
      " 1806 1807 1815] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 7}\n",
      "Validation Metrics for test11: accuracy: 0.48976109215, precision: 0.488715277778, recall: 0.984265734266, auc: 0.5012995338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test11 - GaussianNB, vectorizer with frequency cutoffs, Feature Union\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfNB)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[7, 10, 15])\n",
    "\n",
    "prediction = gridsearch_pipeline('test11', text_train_transformed2, labels_train, text_test_transformed2, steps, params)\n",
    "scoring_function('test11', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 10, 'classifier__alpha': 0.001}\n",
      "Validation Metrics for test12: accuracy: 0.511945392491, precision: 0.0, recall: 0.0, auc: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test12 - svm, vectorizer with frequency cutoffs, selectPercentile\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[5, 10, 15],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test12', text_train_transformed2, labels_train, text_test_transformed2, steps, params)\n",
    "scoring_function('test12', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection__pca__n_components': 100, 'classifier__alpha': 0.001, 'feature_selection__select__percentile': 5}\n",
      "Validation Metrics for test13: accuracy: 0.501706484642, precision: 0.494252873563, recall: 0.902097902098, auc: 0.511048951049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test13 - svm, vectorizer with frequency cutoffs, Feature Union\n",
    "steps = [\n",
    "         ('feature_selection', feature_selection),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_selection__select__percentile=[5, 10, 15], \n",
    "              feature_selection__pca__n_components=[100, 200, 500],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test13', text_train_transformed2, labels_train, text_test_transformed2, steps, params)\n",
    "scoring_function('test13', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding frequency cut-off decreased classifier performance. This may be because stop words were already removed from the data in pre-processing. Now try n-grams with stop words included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing classifier n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "text_nostop = pickle.load(open(\"bow_processed_text_nostop.pkl\", \"r\"))\n",
    "\n",
    "#train/test split of data (randomized)\n",
    "text_train_nostop, text_test_nostop, labels_train_nostop, labels_test_nostop = cross_validation.train_test_split(text_nostop, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688\n"
     ]
    }
   ],
   "source": [
    "#vectorizer with uni-, bi-, and tri-grams\n",
    "text_train_transformed_nostop = vectorizer3.fit_transform(text_train_nostop).toarray()\n",
    "text_test_transformed_nostop  = vectorizer3.transform(text_test_nostop).toarray()\n",
    "print len(text_train_transformed_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [     7      8      9 ..., 227713 227725 227726] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [     1      2     15 ..., 227727 227728 227729] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [     3      4      5 ..., 227721 227723 227724] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 7}\n",
      "Validation Metrics for test15: accuracy: 0.700511945392, precision: 0.693520140105, recall: 0.692307692308, auc: 0.700320512821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test14 - GaussianNB, vectorizer with ngrams, Feature Union\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfNB)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[7, 10, 15])\n",
    "\n",
    "prediction = gridsearch_pipeline('test14', text_train_transformed_nostop, labels_train, text_test_transformed_nostop, steps, params)\n",
    "scoring_function('test14', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [     7      8      9 ..., 227713 227725 227726] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [     1      2     15 ..., 227727 227728 227729] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\JoAnna\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [     3      4      5 ..., 227721 227723 227724] are constant.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 15, 'classifier__alpha': 0.0001}\n",
      "Validation Metrics for test16: accuracy: 0.767918088737, precision: 0.776752767528, recall: 0.736013986014, auc: 0.767173659674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0xb14d4e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test15 - svm, vectorizer with ngrams, selectPercentile\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[12, 15, 17],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test15', text_train_transformed_nostop, labels_train_nostop, text_test_transformed_nostop, steps, params)\n",
    "scoring_function('test15', labels_test_nostop, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection__pca__n_components': 100, 'classifier__alpha': 0.0001, 'feature_selection__select__percentile': 10}\n",
      "Validation Metrics for test17: accuracy: 0.756825938567, precision: 0.784158415842, recall: 0.692307692308, auc: 0.755320512821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0xb0fd898>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test16 - svm, vectorizer with ngrams, Feature Union\n",
    "steps = [\n",
    "         ('feature_selection', feature_selection),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_selection__select__percentile=[10, 15], \n",
    "              feature_selection__pca__n_components=[100, 200, 500],\n",
    "              classifier__alpha=[0.0001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test16', text_train_transformed_nostop, labels_train_nostop, text_test_transformed_nostop, steps, params)\n",
    "scoring_function('test16', labels_test_nostop, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try reducing dimensionality of matrix\n",
    "text_train_transformed_nostop2 = vectorizer4.fit_transform(text_train_nostop).toarray()\n",
    "text_test_transformed_nostop2  = vectorizer4.transform(text_test_nostop).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_pick__percentile': 15, 'classifier__alpha': 0.001}\n",
      "Validation Metrics for test18: accuracy: 0.548634812287, precision: 0.539305301645, recall: 0.515734265734, auc: 0.547867132867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x1f7db9b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test17 - svm, vectorizer with ngrams, selectPercentile\n",
    "steps = [\n",
    "         ('feature_pick', select),\n",
    "         ('classifier', clfSVM)]\n",
    "\n",
    "params = dict(feature_pick__percentile=[12, 15, 17],\n",
    "              classifier__alpha=[0.0001, 0.00001, 0.001])\n",
    "\n",
    "prediction = gridsearch_pipeline('test17', text_train_transformed_nostop2, labels_train, text_test_transformed_nostop2, steps, params)\n",
    "scoring_function('test17', labels_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export table\n",
    "data = scoring_table.get_string()\n",
    "\n",
    "with open('scoring_table.txt', 'wb') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(SAVE_PATH)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#export test 15\n",
    "model = Pipeline([ \n",
    "    ('vectorize', TfidfVectorizer(ngram_range = (1,3), sublinear_tf=True)), \n",
    "    ('select', SelectPercentile(f_classif, percentile=15)), \n",
    "    ('classify', SGDClassifier(loss='modified_huber', penalty='l2', n_iter=200, random_state=42, alpha=0.0001)), \n",
    "])\n",
    "\n",
    "# train the pipeline (note this calls fit_transform on all transformers and fit on the final estimator) \n",
    "model.fit(text_train_nostop, labels_train) \n",
    "\n",
    "# save the entire model \n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load pickled model\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.76      0.78       600\n",
      "          1       0.76      0.80      0.78       572\n",
      "\n",
      "avg / total       0.78      0.78      0.78      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test model on test data\n",
    "prediction = model.predict(text_test_nostop)\n",
    "\n",
    "report = sklearn.metrics.classification_report(labels_test, prediction)\n",
    "print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
